@book{DeepUtopia,
  title={Deep Utopia: Life and Meaning in a Solved World},
  author={Bostrom, Nick},
  year={2024},
  month={March},
  publisher={Ideapress}
}

@online{LovingGrace,
  title={Machines of Loving Grace},
  author={Amodei, Dario},
  date={2024-10-01},
  url = {https://www.darioamodei.com/essay/machines-of-loving-grace},
  urldate = {2025-08-15},
}

@incollection{Yudkowsky2008,
  author    = {Yudkowsky, Eliezer},
  title     = {Artificial Intelligence as a Positive and Negative Factor in Global Risk},
  booktitle = {Global Catastrophic Risks},
  editor    = {Bostrom, Nick and Ćirković, Milan M.},
  pages     = {308--345},
  publisher = {Oxford University Press},
  location  = {New York},
  date      = {2008}
}

@inproceedings{Yampolskiy2016,
  title={Taxonomy of Pathways to Dangerous Artificial Intelligence.},
  author={Yampolskiy, Roman},
  booktitle={AAAI Workshop: AI, Ethics, and Society},
  pages={143--148},
  year={2016}
}

@online{Yudkowsky2022,
  author       = {Yudkowsky, Eliezer},
  title        = {AGI Ruin: A List of Lethalities},
  date         = {2022-06-06},
  url          = {https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities},
  urldate      = {2025-08-15},
}

@book{Bostrom2014,
  author    = {Bostrom, Nick},
  title     = {Superintelligence: Paths, Dangers, Strategies},
  publisher = {Oxford University Press},
  year      = {2014},
}

@book{Tegmark2017,
  title={Life 3.0: Being human in the age of artificial intelligence},
  author={Tegmark, Max},
  year={2017},
  publisher={Knopf Doubleday Publishing Group}
}

@online{Yampolskiy2019,
  author    = {Yampolskiy, Roman},
  title     = {Personal Universes: A Solution to the Multi-Agent Value Alignment Problem},
  year      = {2019},
  eprint    = {1901.01851},
  eprinttype= {arxiv},
  urldate   = {2025-08-16},
  note      = {arXiv:1901.01851 [cs.AI]}
}

@article{VulnerableWorldHypothesis,
author = {Bostrom, Nick},
title = {The Vulnerable World Hypothesis},
journal = {Global Policy},
volume = {10},
number = {4},
pages = {455-476},
doi = {https://doi.org/10.1111/1758-5899.12718},
abstract = {Abstract Scientific and technological progress might change people's capabilities or incentives in ways that would destabilize civilization. For example, advances in DIY biohacking tools might make it easy for anybody with basic training in biology to kill millions; novel military technologies could trigger arms races in which whoever strikes first has a decisive advantage; or some economically advantageous process may be invented that produces disastrous negative global externalities that are hard to regulate. This paper introduces the concept of a vulnerable world: roughly, one in which there is some level of technological development at which civilization almost certainly gets devastated by default, i.e. unless it has exited the ‘semi-anarchic default condition’. Several counterfactual historical and speculative future vulnerabilities are analyzed and arranged into a typology. A general ability to stabilize a vulnerable world would require greatly amplified capacities for preventive policing and global governance. The vulnerable world hypothesis thus offers a new perspective from which to evaluate the risk-benefit balance of developments towards ubiquitous surveillance or a unipolar world order.},
year = {2019}
}

@book{Strugatsky1974DefinitelyMaybe,
  author    = {Arkady Strugatsky and Boris Strugatsky},
  title     = {Definitely Maybe},
  year      = {1978},
  publisher = {Macmillan},
  note      = {Originally published in Russian as \emph{"За миллиард лет до конца света"} (A Billion Years Before the End of the World) in 1974},
  address   = {New York},
}

@article{Wolfram1984CA,
  author    = {Stephen Wolfram},
  title     = {Cellular automata as models of complexity},
  journal   = {Nature},
  year      = {1984},
  volume    = {311},
  number    = {5985},
  pages     = {419--424},
  doi       = {10.1038/311419a0},
  publisher = {Nature Publishing Group},
}

@book{russell2019human,
  title={Human compatible: AI and the problem of control},
  author={Russell, Stuart},
  year={2019},
  publisher={Penguin Uk}
}

@misc{Scott2014Moloch,
  author       = {Scott Alexander},
  title        = {Meditations on Moloch},
  year         = {2014},
  howpublished = {\url{https://slatestarcodex.com/2014/07/30/meditations-on-moloch/}},
  note         = {Blog post on \emph{Slate Star Codex}, published July 30, 2014},
  urldate      = {2025-08-21},
}

@article{grinbaum2013responsible,
  title={What is “responsible” about responsible innovation? Understanding the ethical issues},
  author={Grinbaum, Alexei and Groves, Christopher},
  journal={Responsible innovation: Managing the responsible emergence of science and innovation in society},
  pages={119--142},
  year={2013},
  publisher={Wiley Online Library}
}

@incollection{grinbaum2024responsible,
  title={Responsible research and innovation},
  author={Grinbaum, Alexei},
  booktitle={Handbook of Technology Assessment},
  pages={409--417},
  year={2024},
  publisher={Edward Elgar Publishing}
}
